# sql 튜닝 팁

### 한번에 너무 많은 데이터를 조회하는 건 아닌지 생각하자

- LIMIT, WHERE문 등을 활용해서 한 번에 조회하는 데이터의 수를 줄이는 방법을 고려

### where 문에서의 sql 튜닝 - 1

- WHERE문의 부등호(>, <, ≤, ≥, =), IN, BETWEEN, LIKE와 같은 곳에서 사용되는 컬럼은 인덱스를 사용했을 때 성능이 향상될 가능성이 높다. 
- 최근 3일 이내에 가입한 유저를 조회한다고 가정
- 테이블 생성 쿼리, 100만건의 랜덤 데이터가 있다고 가정

```
CREATE TABLE users (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(100),
    department VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

- 조회 쿼리
```
SELECT * FROM users
WHERE created_at >= DATE_SUB(NOW(), INTERVAL 3 DAY); 
```

![image](https://github.com/user-attachments/assets/aa0b7f4d-c528-4494-b346-84430860569b)


- 실행계획 조회해보기
```
EXPLAIN SELECT * FROM users
WHERE created_at >= DATE_SUB(NOW(), INTERVAL 3 DAY); 
```

![image](https://github.com/user-attachments/assets/9945ed66-43a7-430d-9af4-afc96ebb7766)


- type이 ALL이고 rows가 997,632 -> 풀 테이블 스캔
- 풀 테이블 스캔은 성능상으로 비효율적이다
- created_at이 만약 정렬이 되어 있다면 성능이 훨씬 개선 될 것이다
  - index생성
```
CREATE INDEX idx_created_at ON users (created_at);
```
- 인덱스 생성 후 같은 조회 쿼리를 다시 하면 성능이 훨씬 개선 된 것을 확인할 수 있다.

![image](https://github.com/user-attachments/assets/3d94e0ba-ce37-415d-94cc-0da5d48ac6e6)

- 실행 계획을 다시 조회해 보면

![image](https://github.com/user-attachments/assets/26ccdebf-03f7-491f-9e7e-caedc472c599)

- type이 range -> 인덱스 레인지 스캔 사용됨

### where 문에서의 sql 튜닝 - 2

- Sales 부서이면서 최근 3일 이내에 가입한 유저 조회하기
- 테이블은 앞선 예제와 같다고 가
- 조회 쿼리
```
SELECT * FROM users
WHERE department = 'Sales'
AND created_at >= DATE_SUB(NOW(), INTERVAL 3 DAY)
```

![image](https://github.com/user-attachments/assets/e7b43b43-a0a9-4f6b-8a7f-046dbea1e3b2)

![image](https://github.com/user-attachments/assets/ce82933b-0e96-4812-a1e8-c8b32c0f1b20)

- type이 ALL인걸 보니 풀 테이블 스캔을 했다.
- rows가 996,810인 걸 보니 전체 데이터를 대부분 액세스 했다는 걸 추측할 수 있다. 
- 인덱스를 걸 수 있는 세가지 방법을 생각해 볼 수 있다
  1. `created_at` 컬럼을 기준으로 인덱스 생성
  2. `department` 컬럼을 기준으로 인덱스 생성
  3. `department`, `created_at` 둘 다 인덱스 생성
  
#### created_at 만 생성

![image](https://github.com/user-attachments/assets/4159b2cc-ce93-4eda-97eb-08e6753ce88c)

![image](https://github.com/user-attachments/assets/800e6cbd-b8a9-4231-874a-8ff1c2944719)

- 기존 200ms 응답 속도에서 20ms로 줄어들었으니 약 10배 정도의 성능이 향상됐다.  
- `type`이 `range`로 나온걸로 봐서 인덱스 레인지 스캔을 했다. 그리고 `rows`가 1043이다. 1043개의 데이터에 액세스를 한 것이다.

#### department 만 생성

![image](https://github.com/user-attachments/assets/f9262255-be47-4fad-b80c-5c28b1af1859)

![image](https://github.com/user-attachments/assets/d4dfc9ef-5bef-4690-bdd6-816e9c229a3a)

- 기존 200ms 응답 속도에서 140ms로 성능이 조금 향상됐다.
- type이 ref인 걸로 봐서는 비고유 인덱스로 조회를 했다는 걸 알 수 있다.
- 여기까지는 크게 문제가 없는데 rows가 191,314(추정값)로 크게 잡혀있다.
- 즉, 데이터에 191,314번 액세스 했다는 뜻이다.
- 데이터 액세스를 많이 하면 할수록 시간이 오래 걸려 성능에 안 좋은 영향을 미친다.
- 이런 이유 때문에 created_at에 인덱스를 걸었을 때보다 성능이 덜 향상됐다. EXPLAIN ANALYZE를 통해서도 확인해보자. 

```
-> Filter: (users.created_at >= <cache>((now() - interval 3 day)))  
(cost=8900 rows=63765) (actual time=3.49..121 rows=114 loops=1)
    -> Index lookup on users using idx_department (department='Sales')  
    (cost=8900 rows=191314) (actual time=0.32..111 rows=100000 loops=1)
```

1. `idx_department` 인덱스를 활용해 `department = ’Sales’`를 만족시키는 데이터를 뽑아낸다. 
    
    → 이 때, 액세스한 데이터의 개수는 100,000개이다. (`rows=100000`)
    
2. 액세스한 100,000개의 데이터 중 `users.created_at >= <cache>((now() - interval 3 day))`을 만족하는 데이터를 필터링해온다.
    
    → 조건을 만족하는 데이터 개수는 114개이다.

#### created_at, department 둘다 생성 (멀티 럼 인덱스 X)

![image](https://github.com/user-attachments/assets/4b7457fd-ae58-49de-b664-ab2ebd5686ba)

![image](https://github.com/user-attachments/assets/d79bc43e-d2ed-465d-b9c8-ee5e5a2fa323)

- 기존 200ms 응답 속도에서 20ms로 줄어들었으니 약 10배 정도의 성능이 향상됐다.
- 실행 계획의 결과를 보면 `key`(실제 사용한 인덱스)에 `idx_created_at` 밖에 없다.
- 그 이유는 인덱스가 `idx_department`, `idx_created_at` 이렇게 둘 다 있지만 `idx_created_at`만 사용해서 조회하는 게 빠르다고 판단한 것이다.
- created_at 컬럼 인덱스만 생성한 결과와 동일하다. 
  - **따라서 실질적으로 성능 향상에 큰 효과가 있는 `created_at` 컬럼에 한해서만 인덱스를 생성하는 게 효율적이다.**
  - 중복도가 낮은 컬럼이 효과

#### 멀티 컬럼 인덱스

- (created_at, department) 멀티 컬럼 인덱스 생성

![image](https://github.com/user-attachments/assets/b530fe0a-de9b-4c95-9637-baf0fc44d01e)

- (department, created_at) 멀티 컬럼 인덱스 생성

![image](https://github.com/user-attachments/assets/748e5bbf-ad2b-4bf2-aec2-3edaa9dd03b0)

- 둘다 약 30ms
- 위 2가지 멀티 컬럼 인덱스를 활용해서 설정해봤지만, `created_at` 인덱스만 걸었을 때와 크게 성능 차이가 없다.
- 단일 컬럼에 설정하는 일반 인덱스’를 설정했을 때와 ‘멀티 컬럼 인덱스를 설정했을 때’의 성능 차이가 별로 나지 않는다면, 멀티 컬럼 인덱스를 사용하지 말고 일반 인덱스를 활용하자.

### 인덱스를 걸었는데도 인덱스가 작동하지 않는 경우 - 1

- 테이블, 100만건의 랜덤 데이터가 있다고 가정

```
CREATE TABLE users (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(100),
    age INT
);
```

- 인덱스 생성

```
CREATE INDEX idx_name ON users (name);
```

- 조회 쿼리 실행 계획
```
EXPLAIN SELECT * FROM users 
ORDER BY name DESC;
```

![image](https://github.com/user-attachments/assets/e4f8c43d-b0d2-42ff-8c40-bf6aa75c49b4)

- 분명 인덱스를 걸었음에도 왜 풀 테이블 스캔으로 데이터를 조회함
- 그 이유는 옵티마이저가 넓은 범위의 데이터를 조회할 때는 인덱스를 활용하는 것이 비효율적이라고 판단한다.
- 인덱스를 활용하지 않고 풀 테이블 스캔으로 데이터를 찾을 때 훨씬 효율적이라고 판단한다. 
- 즉, 굳이 인덱스를 거쳤다가 각 원래 테이블의 데이터를 일일이 하나씩 찾아내는 것보다, 바로 원래 테이블에 접근해서 모든 데이터를 통째로 가져와서 정렬하는 게 효율적이라고 판단한 것

### 인덱스를 걸었는데도 인덱스가 작동하지 않는 경우 - 2

- 테이블, 100만건의 랜덤 데이터가 있다고 가정

```
CREATE TABLE users (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(100),
    salary INT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

- 인덱스 생성
```
CREATE INDEX idx_name ON users (name);
CREATE INDEX idx_salary ON users (salary);
```

- 조회 쿼리 실행 계획
```
# User000000으로 시작하는 이름을 가진 유저 조회
EXPLAIN SELECT * FROM users
WHERE SUBSTRING(name, 1, 10) = 'User000000';

# 2달치 급여(salary)가 1000 이하인 유저 조회
SELECT * FROM users
WHERE salary * 2 < 1000
ORDER BY salary;
```

![image](https://github.com/user-attachments/assets/20a46b44-5c5b-46b1-afb0-080a300a0901)


- 풀 테이블 스캔을 활용하게 된다
- SQL문을 작성할 인덱스 컬럼을 가공(함수 적용, 산술 연산, 문자역 조작 등)하면, MySQL은 해당 인덱스를 활용하지 못하는 경우가 많다.
- 따라서 인덱스를 적극 활용하기 위해서는 인덱스 컬럼 자체를 최대한 가공하지 않아야 한다.

- 인덱스 칼럼을 가공해서 사용하지 않도록 sql 수정하기
```
# User000000으로 시작하는 이름을 가진 유저 조회
EXPLAIN SELECT * FROM users
WHERE name LIKE 'User000000%';

# 2달치 급여(salary)가 1000 이하인 유저 조회
EXPLAIN SELECT * FROM users
WHERE salary < 1000 / 2
ORDER BY salary;
```

![image](https://github.com/user-attachments/assets/2025d43b-6273-4ae7-ac39-c4a2bfdf7b4b)

### ORDER BY문이 사용된 SQL문 튜닝하기

- 테이블, 100만건의 랜덤 데이터 있다고 가정
```
CREATE TABLE users (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(100),
    department VARCHAR(100),
    salary INT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

- 조회 쿼리,  실행 계획
```
SELECT * FROM users
ORDER BY salary
LIMIT 100;
```

![image](https://github.com/user-attachments/assets/d5f12cd7-2aa2-45c4-b271-375b5cf3f463)

![image](https://github.com/user-attachments/assets/b6c838a4-55b8-4300-9d02-610498bdd656)

- type이 ALL인걸 보니 풀 테이블 스캔을 했다.
- ORDER BY는 시간이 오래걸리는 작업이므로 최대한 피해주는 것이 좋다.
  - 왜냐하면 정렬이라는 작업 자체가 다른 작업에 비해서 부담스러운 작업이며 성능에 안 좋은 영향을 끼치는 요소 중 하나이기 때문
  - 인덱스를 사용한다면? -> 미리 정렬 되어 있는 상태이게 된다.

- 인덱스 추가
```
CREATE INDEX idx_salary ON users (salary);
```

- 추가 후 같은 조회 쿼리, 실행 계획

![image](https://github.com/user-attachments/assets/9fff37bd-2086-4b3a-b57a-49a4b2548169)

![image](https://github.com/user-attachments/assets/412746b8-5231-4a25-a0eb-d99ee22d476d)

- **풀 테이블 스캔(type: ALL)**이 아닌 **인덱스 풀 스캔(type: index)**을 활용해서 빠르게 데이터를 정렬해서 조회해왔다.
- `LIMIT` 없이 큰 범위의 데이터를 조회해오는 경우 옵티마이저가 인덱스를 활용하지 않고 테이블 풀 스캔을 해버릴 수도 있다.
  - 따라서 성능 효율을 위해 `LIMIT`을 통해 작은 데이터의 범위를 조회해오도록 항상 신경쓰자.

### WHERE 문에 인덱스 걸기 vs ORDER BY 문에 인덱스 걸기

- ORDER BY의 특징 상 모든 데이터를 바탕으로 정렬을 해야 하기 때문에, 인덱스 풀 스캔 또는 테이블 풀 스캔을 활용할 수 밖에 없다.
- 이 때문에 ORDER BY문보다 WHERE문에 있는 컬럼에 인덱스를 걸었을 때 성능이 향상되는 경우가 많다.
- 절대적인 기준은 아니다. 예시를 봐보
- 테이블, 100만건 랜덤 데이터 가정
```
CREATE TABLE users (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(100),
    department VARCHAR(100),
    salary INT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

- 조회 쿼리, 실행 계획
```
SELECT * FROM users
WHERE created_at >= DATE_SUB(NOW(), INTERVAL 3 DAY)
AND department = 'Sales'
ORDER BY salary
LIMIT 100;
```

![image](https://github.com/user-attachments/assets/fd303718-d7e0-4c71-9b92-655d14f93126)

![image](https://github.com/user-attachments/assets/c58a4c0b-130c-4226-a5dc-8355b8b53921)

- 약 200ms정도의 시간
- type은 all -> 풀 테이블 스캔
- 성능 개선을 위한 인덱스 추가
  - SQL문만 봤을 때는 created_at, department, salary 컬럼에 인덱스를 걸 수 있는 선택지가 있다
  - created_at와 department 컬럼 중에서 인덱스를 걸었을 때 효율적인 컬럼은 created_at이라는 걸 예상할 수 있다.
  - 왜냐하면 위의 SQL 문 조건을 봤을 때 department = ‘Sales’의 조건은 데이터 액세스 수가 많을 수 밖에 없다.
  - 하지만 created_at >= DATE_SUB(NOW(), INTERVAL 3 DAY)의 조건은 데이터 액세스 수가 적다.
  - 그렇다면 **created_at이랑 salary** 중에서 인덱스를 걸었을 때 효율적인 컬럼은 어떤 걸까?
 
#### salary에 인덱스 걸기

![image](https://github.com/user-attachments/assets/1bcfd06d-596a-4906-b1d5-84e6f1adbaee)

![image](https://github.com/user-attachments/assets/519cc492-52c1-4a73-b47d-e232605d0f39)

- SQL문의 성능을 측정해보니 5배가 더 느려졌다
- 위의 실행 계획에서 `type`이 `index`이면서 `salary` 인덱스를 사용한 걸로 봐서 인덱스 풀 스캔을 했음을 알 수 있다.

```
-> Limit: 100 row(s) 
 (cost=9.09 rows=3.33) (actual time=23.8..1009 rows=100 loops=1)
    -> Filter: ((users.created_at >= <cache>((now() - interval 3 day))) and (users.department = 'Sales'))  
    (cost=9.09 rows=3.33) (actual time=23.8..1009 rows=100 loops=1)
        -> Index scan on users using idx_salary  
        (cost=9.09 rows=100) (actual time=1.03..943 rows=974891 loops=1)
```

1. `idx_salary` 인덱스를 활용해 인덱스 풀 스캔을 했다. 이 인덱스를 활용했기 때문에 정렬 과정이 따로 필요없다. 
2. 그런 뒤에 `WHERE` 조건을 만족시키는 데이터 100개를 필터링한다. 이 때, **인덱스에는 `created_at`, `department` 정보가 없기 때문에 실제 테이블에 접근해서 조건을 만족하는 지 확인해야한다.** 풀 테이블 스캔과 거의 다를 바가 없다.
3. 조건을 만족시키는 데이터 100개를 찾는 순간 더 이상 탐색을 하지 않는다. (`LIMIT 100`)
- 참고) `LIMIT 100`을 안 달아주면 탐색하는 데이터의 범위가 커져서 풀 테이블 스캔(type: ALL)으로 데이터를 스캔한다.

#### created_at에 인덱스 걸기

![image](https://github.com/user-attachments/assets/7c503f5e-5a50-42c8-b763-c385493baa45)

![image](https://github.com/user-attachments/assets/a1d87d57-4388-497c-a472-458ada271c8f)

- 성능을 측정해보니 200ms보다 약 6~7배 정도 빨라졌음을 알 수 있다.
- type이 range인걸 보니 인덱스 레인지 스캔을 활용했음을 알 수 있다.

```
-> Limit: 100 row(s)  
(cost=504 rows=100) (actual time=8.94..8.96 rows=100 loops=1)
    -> Sort: users.salary, limit input to 100 row(s) per chunk  
    (cost=504 rows=1120) (actual time=8.94..8.95 rows=100 loops=1)
        -> Filter: (users.department = 'Sales')  
        (cost=504 rows=1120) (actual time=0.269..8.84 rows=104 loops=1)
            -> Index range scan on users using idx_created_at over ('2024-06-30 01:21:20' <= created_at), 
            with index condition: (users.created_at >= <cache>((now() - interval 3 day)))  
            (cost=504 rows=1120) (actual time=0.0537..8.54 rows=1120 loops=1)
```

1. `idx_created_at` 인덱스를 활용해 인덱스 레인지 스캔을 했다. 이 때, `users.created_at >= <cache>((now() - interval 3 day))`을 만족하는 데이터에만 액세스했다. (`rows=1120`)
2. 1번 과정에서 액세스한 데이터 중에서 `users.department = ‘Sales’`을 만족하는 데이터를 필터링했다. (`rows=104`)
3. 2번 과정에서 필터링한 104개의 데이터를 `users.salary`를 기준으로 정렬시켰다. 
4. `LIMIT`으로 인해 100개의 데이터만 가져왔다.

### HAVING문이 사용된 sql문 튜닝하기

- 테이블, 100만건의 랜덥 데이터 가정
```
CREATE TABLE users (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(100),
    age INT,
    department VARCHAR(100),
    salary INT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

- 인덱스 생성
```
CREATE INDEX idx_age ON users (age);
```

- 조회 쿼리, 실행 계획
```
SELECT age, MAX(salary) FROM users
GROUP BY age
HAVING age >= 20 AND age < 30;
```

![image](https://github.com/user-attachments/assets/441efbc4-7fac-4ad4-996d-badbe4bd90cc)

![image](https://github.com/user-attachments/assets/e2f29296-c8aa-4fb9-844d-b6deb3341c03)

- 800ms 정도의 시간
- type이 index -> 인덱스 풀 스캔을 하고 있다. 

```
-> Filter: ((users.age >= 20) and (users.age < 30))  (cost=200263 rows=101) (actual time=208..882 rows=10 loops=1)
    -> Group aggregate: max(users.salary)  (cost=200263 rows=101) (actual time=38.4..882 rows=100 loops=1)
        -> Index scan on users using idx_age  (cost=100624 rows=996389) (actual time=1.53..850 rows=1e+6 loops=1)
​
```

- 인덱스 스캔을 하지만 salary의 최댓값을 구하려면 실데 테이블에 접근을 해야 한다.
- 따라서 100만개의 데이터에 쭉 다 접근을 해서 시간이 오래 걸리게 된다.

- 성능 개선하기 **쿼리변경**
```
SELECT age, MAX(salary) FROM users
WHERE age >= 20 AND age < 30
GROUP BY age;
```

![image](https://github.com/user-attachments/assets/a897b16c-602e-46c8-a068-814ead0c8af8)

![image](https://github.com/user-attachments/assets/09258ee6-cf74-4038-94c2-138264e6e8e7)

```
-> Group aggregate: max(users.salary)  (cost=111397 rows=101) (actual time=75.7..198 rows=10 loops=1)
    -> Index range scan on users using idx_age over (20 <= age < 30), 
    with index condition: ((users.age >= 20) and (users.age < 30))  (cost=91143 rows=202540) (actual time=0.582..193 rows=99990 loops=1)
```
- 20살에서 30 이하의 이 조건을 만족시키는 age에 해당하는 인덱스 값만 먼저 갖고 온다.
- 그러다 보니 100만 개의 데이터를 다 읽을 필요 없이, 약 10만 개 정도의 데이터만 가져오면 되는 거예요 줄일 수 있게 됐다.
- 작은 범위의 데이터로 그룹핑을 하기 때문에 그룹핑 작업도 훨씬 간소화 됨

- HAVING문 -> GROUP BY를 처리한 다음에 필터링을 하는 것이다 보니 속도가 느릴 가능성이 크다
- **HAVING문 대신에 WHERE문을 쓸 수 있는 지 체크해보자.**
